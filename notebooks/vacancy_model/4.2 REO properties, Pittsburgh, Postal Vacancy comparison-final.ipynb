{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of vacancy and foreclosures, transactions, sheriff's auctions, and armslength sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Dropbox/largetransfer/luc/carter\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path = '/'.join(os.getcwd().split('/')[:-2])\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113132, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "tci = pd.read_csv(path+'/data/model_data/tci_1_0.csv', parse_dates=['Date'])\n",
    "tci = tci[['parcel','vacant','SPA_NAME','Date']]\n",
    "\n",
    "dates = dict(zip(tci.parcel, tci.Date))\n",
    "print(tci.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assume real estate owned (by companies or banks) are organizations that have these series of letters in their name.\n",
    "def find_REO(s):\n",
    "    if isinstance(s,str):\n",
    "        s = s.lower()\n",
    "        if re.search(\"llc\", s):\n",
    "            return True\n",
    "        if re.search(\"bank\", s):\n",
    "            return True\n",
    "        if re.search(\"mortg\", s):\n",
    "            return True\n",
    "        if re.search(\"mort.\", s):\n",
    "            return True\n",
    "        if re.search(\"comp\", s):\n",
    "            return True\n",
    "        if re.search(\"corp\", s):\n",
    "            return True\n",
    "        if re.search(\"fannie\", s):\n",
    "            return True\n",
    "        if re.search(\"housing\", s):\n",
    "            return True\n",
    "        if re.search(\"sec.\", s):\n",
    "            return True\n",
    "        if re.search(\"loan\", s):\n",
    "            return True\n",
    "        if re.search(\"inc\", s):\n",
    "            return True\n",
    "        if re.search(\"ohio\", s):\n",
    "            return True\n",
    "        if re.search(\"cleveland\", s):\n",
    "            return True\n",
    "        if re.search(\"estate\", s):\n",
    "            return True\n",
    "        if re.search(\"organization\", s):\n",
    "            return True\n",
    "        if re.search(\"develop\", s):\n",
    "            return True\n",
    "        if re.search(\"ltd\", s):\n",
    "            return True\n",
    "        if re.search(\"hsg\", s):\n",
    "            return True\n",
    "        if re.search(\"limited\", s):\n",
    "            return True\n",
    "        if re.search(\"cuyahoga\", s):\n",
    "            return True\n",
    "        if re.search(\"propert\", s):\n",
    "            return True\n",
    "        if re.search(\"invest\", s):\n",
    "            return True\n",
    "        if re.search(\"realt\", s):\n",
    "            return True\n",
    "        if re.search(\"homes\", s):\n",
    "            return True\n",
    "        if re.search(\"neighbor\", s):\n",
    "            return True\n",
    "        return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# METHODOLOGY:\n",
    "\n",
    "# Data included:\n",
    "# Foreclosures\n",
    "# Transfers: filtered for sheriff's deeds (assumed to be sheriff's sales)\n",
    "# Armslength sales\n",
    "\n",
    "# All three datasets are combined such that the dates, parcels, and types are included in the final dataset \n",
    "# Should be encoded as follows: \n",
    "# 0: parcels with no history\n",
    "# 1: foreclosure\n",
    "# 2: sold at sheriff's auction (to a REO entity) – considered to be vacant\n",
    "# 3: sold at armslength (or sold at sheriff's auction to non-REO)\n",
    "\n",
    "# At each date, assign each parcel a number based on the above rubric. The numbers may depend on previous date's \n",
    "# numbers and continue to increment, such that a parcel with the number 4 is in its second foreclosure process\n",
    "\n",
    "\n",
    "fc = pd.read_csv(path+'/data/clean_data/foreclosure_filings2.csv', parse_dates=[2])\n",
    "# fc = fc.sort_values('filedate').groupby('caseno').last()\n",
    "fc = fc.rename(columns={'filedate':'date'})\n",
    "fc['type'] = 'fc'\n",
    "fc = fc[['date','type','parcel']]\n",
    "\n",
    "\n",
    "t = pd.read_csv(path+'/data/clean_data/transfers.csv', parse_dates=['mdate'], dtype=str)\n",
    "t['REO'] = t.GRANTEE1.apply(find_REO)\n",
    "t = t[(t.DEED_TYPE.isin(['Sheriffs Deed',\n",
    " 'Sheriffs Deed Ex']))]\n",
    "t = t[['PROPERTY_NUMBER','mdate','REO']].rename(columns={'PROPERTY_NUMBER':'parcel','mdate':'date'})\n",
    "t['type'] = 't'\n",
    "\n",
    "t.loc[t.REO==False,'type'] = 'al'\n",
    "\n",
    "al = pd.read_csv(path+'/data/clean_data/armslength.csv', dtype=str)\n",
    "al = al.drop_duplicates()\n",
    "\n",
    "# parse armslength dates\n",
    "months = dict(zip(['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'],range(1,13)))\n",
    "def parse_date(x):\n",
    "    day = int(x[0:2])\n",
    "    month = months[x[2:5]]\n",
    "    year = int(x[5:])\n",
    "    return dt.datetime(year,month,day)\n",
    "\n",
    "al['date'] = al.mdate.apply(parse_date)\n",
    "al = al.sort_values('date').rename(columns={'PROPERTY_NUMBER':'parcel'})\n",
    "\n",
    "def parse_amount(x):\n",
    "    return float(str(x)[1:].replace(',',''))\n",
    "\n",
    "al['type'] = 'al'\n",
    "\n",
    "# copies of datasets for finding the vacancy status according to the TCI survey\n",
    "\n",
    "t_copy = pd.merge(t, tci[['parcel','Date']].set_index('parcel'), how='left',left_on='parcel',right_index=True)\n",
    "t_copy = t_copy.loc[(t_copy.date < t_copy.Date)]\n",
    "\n",
    "fc_copy = pd.merge(fc, tci[['parcel','Date']].set_index('parcel'), how='left',left_on='parcel',right_index=True)\n",
    "fc_copy = fc_copy.loc[(fc_copy.date < fc_copy.Date)]\n",
    "\n",
    "al_copy = pd.merge(al, tci[['parcel','Date']].set_index('parcel'), how='left',left_on='parcel',right_index=True)\n",
    "al_copy = al_copy.loc[(al_copy.date < al_copy.Date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = fc[['parcel','date','type']].append(t[['parcel','date','type','REO']]).append(al[['parcel','date','type']])\n",
    "df2 = fc_copy[['parcel','date','type']].append(t_copy[['parcel','date','type','REO']]).append(al_copy[['parcel','date','type']])\n",
    "# df = df.fillna(False)\n",
    "df = df.sort_values(by='date')\n",
    "df2 = df2.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = {0:'al', 1:'fc', 2:'t'}\n",
    "\n",
    "def get_number(x):\n",
    "    for col in range(1,23):\n",
    "        if x.iloc[col] == s[x.iloc[col-1]%3]:\n",
    "            x.iloc[col] = x.iloc[col-1]\n",
    "        elif (s[x.iloc[col-1]%3] == 'fc') & (x.iloc[col] == 't'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+1\n",
    "        elif (s[x.iloc[col-1]%3] == 'fc') & (x.iloc[col] == 'al'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+2\n",
    "        elif (s[x.iloc[col-1]%3] == 't') & (x.iloc[col] == 'al'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+1\n",
    "        elif (s[x.iloc[col-1]%3] == 't') & (x.iloc[col] == 'fc'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+2\n",
    "        elif (s[x.iloc[col-1]%3] == 'al') & (x.iloc[col] == 'fc'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+1\n",
    "        elif (s[x.iloc[col-1]%3] == 'al') & (x.iloc[col] == 't'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+2\n",
    "        else:\n",
    "            x.iloc[col] =  0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REO</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parcel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001-01-003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-12-01</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001-01-004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001-01-005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001-01-008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-12-11</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001-01-009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-06-16</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            REO       date type\n",
       "parcel                         \n",
       "001-01-003  NaN 2005-12-01   al\n",
       "001-01-004  NaN 2007-03-08   al\n",
       "001-01-005  NaN 2015-02-04   al\n",
       "001-01-008  NaN 2003-12-11   al\n",
       "001-01-009  NaN 2014-06-16   al"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tem = df2.groupby('parcel').nth(-1)\n",
    "status.loc[status.iloc[:,0]=='fc', status.columns[0]]  = 1\n",
    "status.loc[status.iloc[:,0]=='t', status.columns[0]] = 2\n",
    "status.loc[status.iloc[:,0]=='al', status.columns[0]] = 0\n",
    "status.loc[status.iloc[:,0].isnull(), status.columns[0]]  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-10-01 00:00:00 2738\n",
      "2010-01-01 00:00:00 2697\n",
      "2010-04-01 00:00:00 2764\n",
      "2010-07-01 00:00:00 2751\n",
      "2010-10-01 00:00:00 2799\n",
      "2011-01-01 00:00:00 3024\n",
      "2011-04-01 00:00:00 3099\n",
      "2011-07-01 00:00:00 3049\n",
      "2011-10-01 00:00:00 3117\n",
      "2012-01-01 00:00:00 3217\n",
      "2012-04-01 00:00:00 3200\n",
      "2012-07-01 00:00:00 3308\n",
      "2012-10-01 00:00:00 3434\n",
      "2013-01-01 00:00:00 3523\n",
      "2013-04-01 00:00:00 3611\n",
      "2013-07-01 00:00:00 3556\n",
      "2013-10-01 00:00:00 3554\n",
      "2014-01-01 00:00:00 3605\n",
      "2014-04-01 00:00:00 3770\n",
      "2014-07-01 00:00:00 3903\n",
      "2014-10-01 00:00:00 4024\n",
      "2015-01-01 00:00:00 4153\n",
      "2015-04-01 00:00:00 4433\n"
     ]
    }
   ],
   "source": [
    "rng = pd.date_range('10/1/2009', periods=23, freq='3MS')\n",
    "status = tci[['parcel']].copy()\n",
    "\n",
    "for date in rng:\n",
    "    tem = df[df.date < date].groupby('parcel').nth(-1)\n",
    "    status = pd.merge(status, tem[['type']], how='left',left_on='parcel', right_index=True)\n",
    "    status = status.rename(columns={'type':date})\n",
    "    print(date, len(tem[tem.REO==True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status = status.set_index('parcel')\n",
    "status_copy = status.copy()\n",
    "status.loc[status.iloc[:,0]=='fc', status.columns[0]]  = 1\n",
    "status.loc[status.iloc[:,0]=='t', status.columns[0]] = 2\n",
    "status.loc[status.iloc[:,0]=='al', status.columns[0]] = 0\n",
    "status.loc[status.iloc[:,0].isnull(), status.columns[0]]  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = {0:'al', 1:'fc', 2:'t'}\n",
    "\n",
    "def get_number(x):\n",
    "    for col in range(1,23):\n",
    "        if x.iloc[col] == s[x.iloc[col-1]%3]:\n",
    "            x.iloc[col] = x.iloc[col-1]\n",
    "        elif (s[x.iloc[col-1]%3] == 'fc') & (x.iloc[col] == 't'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+1\n",
    "        elif (s[x.iloc[col-1]%3] == 'fc') & (x.iloc[col] == 'al'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+2\n",
    "        elif (s[x.iloc[col-1]%3] == 't') & (x.iloc[col] == 'al'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+1\n",
    "        elif (s[x.iloc[col-1]%3] == 't') & (x.iloc[col] == 'fc'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+2\n",
    "        elif (s[x.iloc[col-1]%3] == 'al') & (x.iloc[col] == 'fc'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+1\n",
    "        elif (s[x.iloc[col-1]%3] == 'al') & (x.iloc[col] == 't'):\n",
    "            x.iloc[col] =  x.iloc[col-1]+2\n",
    "        else:\n",
    "            x.iloc[col] =  0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "status2 = status.apply(get_number, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status2.to_csv(path+'/data/clean_data/parcel_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = pd.read_csv(path+'/data/clean_data/parcel_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = dfs.set_index('parcel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009-10-01    2738\n",
       "2010-01-01    2697\n",
       "2010-04-01    2764\n",
       "2010-07-01    2751\n",
       "2010-10-01    2799\n",
       "2011-01-01    3024\n",
       "2011-04-01    3099\n",
       "2011-07-01    3049\n",
       "2011-10-01    3117\n",
       "2012-01-01    3217\n",
       "2012-04-01    3200\n",
       "2012-07-01    3308\n",
       "2012-10-01    3434\n",
       "2013-01-01    3523\n",
       "2013-04-01    3611\n",
       "2013-07-01    3556\n",
       "2013-10-01    3554\n",
       "2014-01-01    3605\n",
       "2014-04-01    3770\n",
       "2014-07-01    3903\n",
       "2014-10-01    4024\n",
       "2015-01-01    4153\n",
       "2015-04-01    4433\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((dfs%3)==2).apply(sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
