{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data used in vacancy model based on TCI parcel numbers\n",
    "\n",
    "Parcels surveyed in Summer 2015 so all data pulled should come from before that. Goal of script/notebook is to filter datasets by the parcel numbers in the TCI survey, although we will filter again based on existence of structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Dropbox/largetransfer/luc/carter\n"
     ]
    }
   ],
   "source": [
    "path = '/'.join(os.getcwd().split('/')[:-1])\n",
    "print path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    }
   ],
   "source": [
    "# get survey data\n",
    "\n",
    "tci = pd.read_csv(path+'/data/inspection_data/full_tci_survey_prelim.csv')\n",
    "\n",
    "ppns = set(tci['ppn'])\n",
    "ppns_nodash = set(tci['ppn'].apply(lambda x: str(x).replace('-','')))\n",
    "\n",
    "# tci[['ppn']].to_csv(path+'/data/original_data/ppns.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122560, 65)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[main.pclass=='Residential'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131522,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tci[tci.USE_CLASS=='R'].ppn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120736"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(main[main.pclass=='Residential'].parcel).intersection(set(tci[tci.USE_CLASS=='R'].ppn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Parcel ID', u'Date', u'USE_CLASS', u'Ward', u'Label', u'SPA_NAME',\n",
       "       u'Address', u'Survey Category', u'Survey Result', u'Open Vacant',\n",
       "       u'For Sale or Rent', u'Apparent Property Use',\n",
       "       u'Apparent Property Capacity', u'House Number Visible/Premises ID',\n",
       "       u'Boarded Windows or Doors', u'Broken Windows', u'Roof Damage',\n",
       "       u'Chimney Damage', u'Paint or Siding Damage',\n",
       "       u'Gutters or Downspout Damage', u'Porch Damage', u'Garage Damage',\n",
       "       u'Dumping (Trash/Debris)', u'Sidewalk Condition', u'Street Tree',\n",
       "       u'Notes', u'Image', u'ppn', u'vacant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tci.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracts = pd.read_csv(path+'/data/original_data/clv_par_census.csv')\n",
    "demo = pd.read_csv(path+'/data/original_data/sociodemographic_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracts = pd.merge(tracts, demo, left_on='NAME10', right_on='Census Tract', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177527, 43)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracts.iloc[:,[0,5,7,9,11,13,14,15,16,17,18,20,22,24,26,28,30,32,34,36,38,40]].to_csv(path+'/data/clean_data/demographic.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_vacant(x):\n",
    "#     if x == 'Occupied Structure':\n",
    "#         return 0\n",
    "#     elif x == 'Vacant Structure':\n",
    "#         return 1\n",
    "#     else: \n",
    "#         return -1\n",
    "    \n",
    "# tci['vacant'] = tci['Survey Category'].apply(get_vacant)\n",
    "# tci.to_csv(path+'/data/inspection_data/full_tci_survey_prelim.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# infile = path+'/data/original_data/main_prop.csv'\n",
    "# outfile = path+'/data/clean_data/main_prop.csv'\n",
    "\n",
    "# with open(infile, 'r') as fin, open(outfile, 'w') as fout:\n",
    "#     write_to = csv.writer(fout, lineterminator='\\n')\n",
    "#     header = next(csv.reader(fin))\n",
    "#     write_to.writerow(header)\n",
    "#     for row in csv.reader(fin):\n",
    "#         if row[0] in ppns:\n",
    "#             write_to.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# commented code only needs to be run once\n",
    "\n",
    "main = pd.read_csv(path+'/data/clean_data/main_prop3.csv', dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         001-01-001\n",
       "1         001-01-003\n",
       "2         001-01-004\n",
       "3         001-01-005\n",
       "4         001-01-006\n",
       "5         001-01-007\n",
       "6         001-01-008\n",
       "7         001-01-009\n",
       "8         001-01-010\n",
       "9         001-01-011\n",
       "10        001-01-012\n",
       "11        001-01-013\n",
       "12        001-01-014\n",
       "13        001-01-015\n",
       "14        001-01-016\n",
       "15        001-01-017\n",
       "16        001-01-018\n",
       "17        001-01-020\n",
       "18        001-01-021\n",
       "19        001-01-023\n",
       "20        001-01-024\n",
       "21        001-01-025\n",
       "22        001-01-026\n",
       "23        001-01-027\n",
       "24        001-01-028\n",
       "25        001-01-029\n",
       "26        001-01-030\n",
       "27        001-01-031\n",
       "28        001-01-032\n",
       "29        001-01-033\n",
       "             ...    \n",
       "452242    735-22-008\n",
       "452243    735-22-009\n",
       "452244    735-22-010\n",
       "452245    735-22-011\n",
       "460530    761-01-019\n",
       "461516    761-11-015\n",
       "461524    761-11-023\n",
       "461525    761-11-024\n",
       "461526    761-11-025\n",
       "461527    761-11-026\n",
       "461528    761-11-027\n",
       "461529    761-11-028\n",
       "461530    761-11-029\n",
       "461531    761-11-030\n",
       "461532    761-11-031\n",
       "461533    761-11-032\n",
       "461534    761-11-033\n",
       "461535    761-11-034\n",
       "461536    761-11-035\n",
       "461628    761-13-001\n",
       "461629    761-13-002\n",
       "461630    761-13-003\n",
       "461669    761-13-042\n",
       "461670    761-13-043\n",
       "461672    761-13-045\n",
       "461673    761-13-046\n",
       "461776    761-15-007\n",
       "461777    761-15-008\n",
       "461919    761-15-150\n",
       "461920    761-15-151\n",
       "Name: parcel, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main[main.pclass=='Residential'].parcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main = main.groupby('parcel').first().reset_index()\n",
    "main = main[main.parcel.isin(ppns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main = main.sort('taxyr', ascending=False)\n",
    "main = main.groupby('parcel').first().reset_index()\n",
    "main = main[main.parcel.isin(ppns)]\n",
    "main.to_csv(path+'/data/clean_data/main_prop_filtered.csv', index=False)\n",
    "\n",
    "# main = pd.read_csv(path+'/data/clean_data/main_prop_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residential characteristics \n",
    "Filename: ```res2013.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first part only needs to be run once\n",
    "\n",
    "# res = pd.read_csv(path+'/data/original_data/res2013.csv')\n",
    "# res = res[res.parcel.isin(ppns)]\n",
    "# res.to_csv(path+'/data/clean_data/res.csv', index=False)\n",
    "\n",
    "res = pd.read_csv(path+'/data/clean_data/res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tax bill\n",
    "Filename: ```dec14_tci.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only needs to be run once to clean taxbill data\n",
    "\n",
    "# infile = path+'/data/original_data/dec14.csv'\n",
    "# outfile = path+'/data/clean_data/taxbill_dec14.csv'\n",
    "\n",
    "# with open(infile, 'r') as fin, open(outfile, 'w') as fout:\n",
    "#     write_to = csv.writer(fout, lineterminator='\\n')\n",
    "#     header = next(csv.reader(fin))\n",
    "#     write_to.writerow(header)\n",
    "#     for row in csv.reader(fin):\n",
    "#         if row[5] in ppns:\n",
    "#             write_to.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb = pd.read_csv(path+'/data/clean_data/taxbill_dec14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.LOCATION_CITY = tb.LOCATION_CITY.apply(lambda x: x.lower())\n",
    "tb.MAIL_CITY = tb.MAIL_CITY.apply(lambda x: x.lower())\n",
    "\n",
    "tb.LOCATION_STATE = tb.LOCATION_STATE.apply(lambda x: x.lower() if isinstance(x,str) else 'l' )\n",
    "tb.MAIL_STATE = tb.MAIL_STATE.apply(lambda x: x.lower() if isinstance(x,str) else 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cities(x):\n",
    "    if x.LOCATION_CITY != x.MAIL_CITY:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def states(x):\n",
    "    if x.LOCATION_STATE != x.MAIL_STATE:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "tb['same_states'] = tb.apply(states, axis=1)\n",
    "tb['same_cities'] = tb.apply(cities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['PROPERTY_NUMBER','LENDER_PROCESS_TYPE','TOTAL_NET_DELQ_BALANCE',\\\n",
    "        'GRAND_TOTAL_BALANCE','FORECLOSURE_FLAG','HOMESTEAD_FLAG','PAYMENT_PLAN_FLAG','same_states','same_cities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb[cols].to_csv('clean_data/taxbill_collinwood.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County land bank\n",
    "Filename: ```count_land_bank.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lb = pd.read_csv(path+'/data/original_data/count_land_bank.csv', parse_dates=[3,4])\n",
    "lb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lb = lb[lb['parcel'].isin(ppns)]\n",
    "lb[lb['acq_dt']<np.datetime64('2015-06-01')].to_csv(path+'/data/clean_data/county_lb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreclosure filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc = pd.read_csv(path+'/data/original_data/foreclosure_filings2006_dec2014.csv', parse_dates = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc = fc[fc['parcel'].isin(ppns)]\n",
    "fc = fc[fc['filedate']<np.datetime64('2015-06-01')]\n",
    "fc.to_csv(path+'/data/clean_data/foreclosure_filings.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sheriff auction\n",
    "Filename: ```shf_aution_mar2000_dec2014.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sa = pd.read_csv(path+'/data/original_data/shf_aution_mar2000_dec2014.csv', parse_dates=[2])\n",
    "\n",
    "sa = sa[sa.parcel.isin(ppns)]\n",
    "sa = sa[sa.salesdt<np.datetime64('2015-06-01')]\n",
    "\n",
    "# sa.loc[sa['ssold'].isnull(),'ssold'] = 'No'\n",
    "# sa.sold_amt = sa.sold_amt.apply(lambda x: float(x.strip('$').replace(',','') if isinstance(x,str) else np.nan))\n",
    "\n",
    "# def convert(x):\n",
    "#     if x == 'No':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "    \n",
    "# sa['ssold'] = sa['ssold'].apply(convert)\n",
    "\n",
    "sa.to_csv(path+'/data/clean_data/sheriff_auction.csv', index=False)\n",
    "\n",
    "# sa = pd.read_csv('clean_data/sa_tci.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfers\n",
    "Filename: ```transfers2000_2014.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile = path+'/data/original_data/transfers2000_2014.csv'\n",
    "outfile = path+'/data/clean_data/transfers.csv'\n",
    "\n",
    "with open(infile, 'r') as fin, open(outfile, 'w') as fout:\n",
    "    write_to = csv.writer(fout, lineterminator='\\n')\n",
    "    header = next(csv.reader(fin))\n",
    "    write_to.writerow(header)\n",
    "    for row in csv.reader(fin):\n",
    "        if row[5] in ppns:\n",
    "            write_to.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = pd.read_csv(path+'/data/clean_data/transfers.csv',parse_dates=[8])\n",
    "tf = tf[tf.mdate<np.datetime64('2015-06-01')]\n",
    "\n",
    "tf.to_csv(path+'/data/clean_data/transfers.csv',index=False)\n",
    "\n",
    "# tf_count = tf[['PROPERTY_NUMBER','WHS_ID']].groupby('PROPERTY_NUMBER').count()\n",
    "# tf_count.columns = ['tf_count']\n",
    "# tf = tf.sort('mdate', ascending=False).groupby('PROPERTY_NUMBER').first().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armslength sales\n",
    "Filename: ```armslengthsales2006_2014.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (10,32,33,35,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    }
   ],
   "source": [
    "al = pd.read_csv(path+'/data/original_data/armslengthsales2006_2014.csv')\n",
    "al = al[al.PROPERTY_NUMBER.isin(ppns)]\n",
    "al.to_csv(path+'/data/clean_data/armslength.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "al = pd.read_csv(path+'/data/clean_data/armslength.csv', parse_dates=['mdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violations\n",
    "Filename: ```violate_cle.csv```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile = path+'/data/original_data/violate_cle.csv'\n",
    "outfile = path+'/data/clean_data/violations.csv'\n",
    "\n",
    "v = pd.read_csv(infile, parse_dates=[1,4])\n",
    "v = v[v.parcel.isin(ppns)]\n",
    "v = v[(v.v_file_date < np.datetime64('2015-06-01')) & (v.v_file_date > np.datetime64('2006-06-01'))]\n",
    "\n",
    "v.to_csv(path+'/data/clean_data/violations.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complaints\n",
    "Filename: ```complaint_cle.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = pd.read_csv(path+'/data/original_data/complaint_cle.csv', parse_dates=[1])\n",
    "\n",
    "c = c[c.parcel.isin(ppns)]\n",
    "c = c[(c.c_file_date < np.datetime64('2014-03-01')) & (c.c_file_date > np.datetime64('2006-03-01'))]\n",
    "\n",
    "c.to_csv(path+'/data/clean_data/complaints.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postal data\n",
    "Filenames: ```pv201302.csv, pv201304.csv, pv201308.csv, pv201312.csv, pv201402.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos1 = pd.read_csv(path+'/data/original_data/pv201302.csv')\n",
    "pos1['date'] = np.datetime64('2013-02-01')\n",
    "pos2 = pd.read_csv(path+'/data/original_data/pv201304.csv')\n",
    "pos2['date'] = np.datetime64('2013-04-01')\n",
    "pos3 = pd.read_csv(path+'/data/original_data/pv201308.csv')\n",
    "pos3['date'] = np.datetime64('2013-08-01')\n",
    "pos4 = pd.read_csv(path+'/data/original_data/pv201312.csv')\n",
    "pos4['date'] = np.datetime64('2013-12-01')\n",
    "pos5 = pd.read_csv(path+'/data/original_data/pv201402.csv')\n",
    "pos5['date'] = np.datetime64('2014-02-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = pos1.append(pos2).append(pos3).append(pos4).append(pos5)\n",
    "p = p[p.PARCEL.isin(ppns)]\n",
    "p.to_csv(path+'/data/clean_data/postal_vacancy.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
